{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from src.const import AUDIO_PATH, MAIN_LABELS, BATCH_SIZE, VALIDATION_SPLIT, SEED\n",
    "from src.preprocess import load_and_preprocess, transform_to_data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown vs known task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading augmented data...\n",
      "Found 64721 files belonging to 30 classes.\n",
      "Using 51777 files for training.\n",
      "Using 12944 files for validation.\n",
      "Finished\n",
      "Creating data with only main classes...\n",
      "Finished\n",
      "Creating binary dataset...\n",
      "Finished\n",
      "Creating main dataset...\n",
      "Found 64721 files belonging to 30 classes.\n",
      "Using 51777 files for training.\n",
      "Using 12944 files for validation.\n",
      "Finished\n",
      "Transforming audio data to spectograms...\n",
      "Finished\n",
      "Augmenting spectograms...\n",
      "Finished\n",
      "Transforming data to numpy arrays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 70773/70773 [04:04<00:00, 289.59it/s] \n",
      "Processing dataset: 100%|██████████| 12944/12944 [00:17<00:00, 742.85it/s]\n",
      "Processing dataset: 100%|██████████| 37992/37992 [01:02<00:00, 605.46it/s] \n",
      "Processing dataset: 100%|██████████| 12944/12944 [00:15<00:00, 818.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "train_ds_bin_X, train_ds_bin_y, val_ds_bin_X, val_ds_bin_y, train_ds_main_X, train_ds_main_y, val_ds_main_X, val_ds_main_y = load_and_preprocess(plot_samples = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds_bin_X[val_ds_bin_X == -np.inf] = np.min(train_ds_bin_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/arrays/train_ds_bin_X.npy', train_ds_bin_X)\n",
    "np.save('data/arrays/train_ds_bin_y.npy', train_ds_bin_y)\n",
    "np.save('data/arrays/val_ds_bin_X.npy', val_ds_bin_X)\n",
    "np.save('data/arrays/val_ds_bin_y.npy', val_ds_bin_y)\n",
    "np.save('data/arrays/train_ds_main_X.npy', train_ds_main_X)\n",
    "np.save('data/arrays/train_ds_main_y.npy', train_ds_main_y)\n",
    "np.save('data/arrays/val_ds_main_X.npy', val_ds_main_X)\n",
    "np.save('data/arrays/val_ds_main_y.npy', val_ds_main_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_bin_X = np.load('data/arrays/train_ds_bin_X.npy')\n",
    "train_ds_bin_y = np.load('data/arrays/train_ds_bin_y.npy')\n",
    "val_ds_bin_X = np.load('data/arrays/val_ds_bin_X.npy')\n",
    "val_ds_bin_y = np.load('data/arrays/val_ds_bin_y.npy')\n",
    "train_ds_main_X = np.load('data/arrays/train_ds_main_X.npy')\n",
    "train_ds_main_y = np.load('data/arrays/train_ds_main_y.npy')\n",
    "val_ds_main_X = np.load('data/arrays/val_ds_main_X.npy')\n",
    "val_ds_main_y = np.load('data/arrays/val_ds_main_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = transform_to_data_loader(train_ds_bin_X, train_ds_bin_y, device=device)\n",
    "val_loader = transform_to_data_loader(val_ds_bin_X, val_ds_bin_y, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            batch_first=True, \n",
    "            bidirectional=True, \n",
    "            num_layers=2\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(2*hidden_size, 64)  # *2 because of bidirectional\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM2(nn.Module):\n",
    "    def __init__(self, sizes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=sizes[0], \n",
    "            hidden_size=sizes[1], \n",
    "            batch_first=True, \n",
    "            bidirectional=True, \n",
    "            num_layers=2\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = [nn.Linear(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)]\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        for layer in self.fc[:-1]:\n",
    "            out = layer(out)\n",
    "            out = self.dropout(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        out = self.fc[-1](out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 128\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "\n",
    "model = BiLSTM(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM2(\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM2([input_size, hidden_size, output_size]).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 5/277 [00:00<00:29,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0209, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(3.5733, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9956, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8507, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7488, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8397, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8245, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5%|▌         | 15/277 [00:00<00:11, 23.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6997, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7208, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7064, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6947, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6973, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6989, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9%|▉         | 25/277 [00:01<00:07, 32.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6952, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11%|█         | 30/277 [00:01<00:07, 34.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6725, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6967, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6728, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14%|█▍        | 40/277 [00:01<00:06, 37.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6964, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6699, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6756, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  17%|█▋        | 48/277 [00:01<00:05, 38.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6685, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6934, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7000, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6705, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6701, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  19%|█▉        | 53/277 [00:01<00:05, 39.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6736, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6779, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  20%|█▉        | 55/277 [00:02<00:09, 22.75it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_X\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\izate\\anaconda3\\envs\\dl2\\lib\\site-packages\\torch\\_tensor.py:461\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    458\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    459\u001b[0m     )\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\izate\\anaconda3\\envs\\dl2\\lib\\site-packages\\torch\\_tensor_str.py:677\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    676\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\izate\\anaconda3\\envs\\dl2\\lib\\site-packages\\torch\\_tensor_str.py:597\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    596\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 597\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    600\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32mc:\\Users\\izate\\anaconda3\\envs\\dl2\\lib\\site-packages\\torch\\_tensor_str.py:349\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    347\u001b[0m     )\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32mc:\\Users\\izate\\anaconda3\\envs\\dl2\\lib\\site-packages\\torch\\_tensor_str.py:137\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "no_improve_count = 0\n",
    "\n",
    "# Training\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch_X, batch_y in tqdm(train_loader, f\"Epoch {epoch}\"):\n",
    "        model.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Loss\n",
    "        print(loss)\n",
    "        train_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "        # Accuracy\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_train += (predicted == batch_y.unsqueeze(1)).sum().item()\n",
    "        total_train += batch_y.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = correct_train / total_train\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "            \n",
    "            # Loss\n",
    "            print(loss)\n",
    "            val_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "            # Accuracy\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_val += (predicted == batch_y.unsqueeze(1)).sum().item()\n",
    "            total_val += batch_y.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = correct_val / total_val\n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{50}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}')\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_count = 0\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "    \n",
    "    if no_improve_count >= patience:\n",
    "        print('Early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
